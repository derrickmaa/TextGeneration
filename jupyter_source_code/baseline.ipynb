{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import math\n",
    "import time\n",
    "import torchtext.vocab as vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "BATCH_SIZE = 20\n",
    "HIDDEN_SIZE = 512\n",
    "N_EPOCHS = 50\n",
    "CLIP = 1\n",
    "LEARNING_RATE = 4e-4 \n",
    "#ENC_DROPOUT = 0.2\n",
    "#DEC_DROPOUT = 0.2\n",
    "TEACH_RATE = 1\n",
    "LAMBDA_COVERAGE = 1\n",
    "GENERATION_LEN = 80\n",
    "#PRE_EMBEDDING_SIZE = 200\n",
    "TRAINING_DATA_PATH = 'c:/users/derri/PycharmProjects/exp/expdata/checklist/baselinedata12_8.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Field(truncate_first=80, fix_length=80)\n",
    "\n",
    "train_data = TabularDataset(\n",
    "        path=TRAINING_DATA_PATH,\n",
    "        format='csv',\n",
    "        fields=[('src', DATA), ('tgt', DATA)],\n",
    "        skip_header = True)\n",
    "\n",
    "DATA.build_vocab(train_data, min_freq=1)\n",
    "\n",
    "DATA_SIZE = len(DATA.vocab)\n",
    "\n",
    "print(DATA_SIZE)\n",
    "\n",
    "train_dataloader = BucketIterator(\n",
    "    train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.src_embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.enc_hid_out = nn.Linear(hidden_size*2, hidden_size, bias=False)\n",
    "        self.enc_out_out = nn.Linear(hidden_size*2, hidden_size, bias=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        s_l, batch_size = src.size()\n",
    "\n",
    "        src_emb = self.src_embedding(src) # src_len, batch, hidden\n",
    "        enc_output, enc_hidden = self.rnn(src_emb) # src_len, batch, hidden*2; 2, batch, hidden\n",
    "        enc_hidden = torch.cat([enc_hidden[0:enc_hidden.size(0):2],\n",
    "                                enc_hidden[1:enc_hidden.size(0):2]], 2) # 1, batch, hidden*2\n",
    "        enc_a = torch.cat([enc_output[:,:,:self.hidden_size],\n",
    "                          enc_output[:,:,self.hidden_size:]], 2) # src_len, batch, hidden*2\n",
    "\n",
    "        enc_out = self.enc_out_out(enc_a).view(s_l, batch_size, self.hidden_size) # src_len, batch, hidden\n",
    "        #enc_out = self.dropout(enc_out)\n",
    "        enc_hid = self.enc_hid_out(enc_hidden) # 1, batch, hidden\n",
    "\n",
    "        return enc_out, enc_hid # src_len, batch, hidden; 1, batch, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear_query = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.linear_context = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.linear_out = nn.Linear(hidden_size*2, hidden_size, bias=True)\n",
    "        self.linear_cover = nn.Linear(1, hidden_size, bias=False)\n",
    "        \n",
    "    def score(self, a_d_o, a_e_o):\n",
    "        batch_size, tgt_len, _ = a_d_o.size()\n",
    "        src_len = a_e_o.size(1)\n",
    "        a1 = self.linear_query(a_d_o.view(-1, self.hidden_size)) # batch*tgt_len, hidden\n",
    "        a1 = a1.view(batch_size, tgt_len, 1, self.hidden_size) # batch, tgt_len, 1, hidden\n",
    "        a1 = a1.expand(batch_size, tgt_len, src_len, self.hidden_size) # batch, tgt_len, src_len, hidden\n",
    "        \n",
    "        \n",
    "        a2 = self.linear_context(a_e_o.contiguous().view(-1, self.hidden_size)) # batch*src_len, hidden \n",
    "        a2 = a2.view(batch_size, 1, src_len, self.hidden_size)\n",
    "        a2 = a2.expand(batch_size, tgt_len, src_len, self.hidden_size) # batch, tgt_len, src_len, hidden\n",
    "        \n",
    "        a = torch.tanh(a1 + a2) # batch, tgt_len, src_len, hidden_size\n",
    "\n",
    "        return self.v(a.view(-1, self.hidden_size)).view(batch_size, tgt_len, src_len) # batch, tgt_len, src_len\n",
    "    \n",
    "    def forward(self, attn_dec_state, attn_enc_state, attn_coverage):\n",
    "\n",
    "        d_o = attn_dec_state.permute(1, 0, 2) # batch, tgt_len, hidden\n",
    "        e_o = attn_enc_state.permute(1, 0, 2) # batch, src_len, hidden\n",
    "        batch_size, target_l, _= d_o.size()\n",
    "        source_l = e_o.size(1)\n",
    "        if attn_coverage is not None:\n",
    "            cover = attn_coverage.view(-1).unsqueeze(1) # tgt_len*batch*src_len, 1(tgt_len=1)\n",
    "            a_o = self.linear_cover(cover).view(batch_size, source_l, self.hidden_size) # batch, src_len, hidden\n",
    "            e_o = e_o + a_o # batch, src_len, hidden\n",
    "            e_o = torch.tanh(e_o) # batch, src_len, hidden \n",
    "        align = self.score(d_o.contiguous(), e_o.contiguous()) # batch, tgt_len, src_len\n",
    "        align_vectors = F.softmax(align.view(batch_size*target_l, source_l), -1) # batch*tgt_len, src_len\n",
    "        align_vectors = align_vectors.view(batch_size, target_l, source_l) # batch, tgt_len, src_len\n",
    "        c = torch.bmm(align_vectors, e_o)# batch, tgt_len, hidden\n",
    "\n",
    "        # concatenate\n",
    "        concat_c = torch.cat([c, d_o], 2).view(batch_size*target_l, self.hidden_size*2) # batch, tgt_len, hidden*2\n",
    "        attn_h = self.linear_out(concat_c).view(batch_size, target_l, self.hidden_size) # batch, tgt_len, hidden\n",
    "        attn_h2 = attn_h.permute(1, 0, 2).contiguous() # tgt_len, batch, hidden\n",
    "        align_vectors2 = align_vectors.permute(1, 0, 2).contiguous() # tgt_len, batch, src_len\n",
    "        return attn_h2, align_vectors2 # tgt_len, batch, hidden; tgt_len, batch, src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attention, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.GRU = nn.GRU(hidden_size, hidden_size)\n",
    "        self.attn = attention\n",
    "        self.dec_out = nn.Linear(hidden_size, output_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, dec_tgt, dec_hidden, attn_memory, dec_g_t, teach, coverage, dec_coverage=True): # dec_g_t is ground truth\n",
    "        if dec_g_t == None:\n",
    "            dec_emb = self.embedding(dec_tgt) # 1, batch, hidden\n",
    "        else:\n",
    "            if random.random() <= teach:\n",
    "                dec_emb = self.embedding(dec_g_t) # 1, batch, hidden\n",
    "            else:\n",
    "                dec_emb = self.embedding(dec_tgt) # 1, batch, hidden\n",
    "        dec_output, dec_hidden = self.GRU(dec_emb, dec_hidden) # tgt_len, batch, hidden; 1, batch, hidden\n",
    "        dec_output_attn, dec_cov = self.attn(dec_output, attn_memory, coverage) # tgt_len, batch, hidden; tgt_len, batch, src_len\n",
    "        if dec_coverage:\n",
    "            coverage = dec_cov if coverage is None else dec_cov + coverage # tgt_len, batch, src_len\n",
    "        dec_out = self.dec_out(dec_output_attn.contiguous().view(-1, self.hidden_size)) # tgt_len, batch, output\n",
    "        #dec_out = self.dropout(dec_out)\n",
    "        \n",
    "        return dec_out, dec_hidden, dec_cov, coverage # tgt_len, batch, output; 1, batch, hidden; tgt_len, batch, src_len; tgt_len, batch, src_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2S(nn.Module):\n",
    "    def __init__(self, encoder, decoder, output_size, gen_len):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.output_size = output_size\n",
    "        self.gen_len = gen_len-1\n",
    "                \n",
    "    def forward(self, src, tgt, teach):\n",
    "        attns = {}\n",
    "        attns[\"std\"] = []\n",
    "        attns[\"coverage\"] = []\n",
    "        tgt_len, batch_size = tgt.size()\n",
    "        encoder_output, encoder_hidden = self.encoder(src) # hidden; 1, batch, hidden\n",
    "        decoder_hidden = encoder_hidden.view(1, batch_size, -1) # 1, batch, hidden\n",
    "        decoder_outputs = torch.ones(self.gen_len, batch_size, self.output_size, device=device) # tgt_len-1, batch\n",
    "        tgt_start = torch.full((1, batch_size), 2, dtype=torch.long, device=device) # 1, batch\n",
    "        decoder_attn_coverage = None\n",
    "        for i in range(tgt_len-1):\n",
    "            if i == 0:\n",
    "                current_tgt = tgt_start # 1, batch\n",
    "                g_t = None\n",
    "            elif i > 0: #and random.random() <= 0.7:\n",
    "                g_t = tgt[i].view(1, batch_size) # 1, batch\n",
    "            decoder_output, decoder_hidden, decoder_attn_std, decoder_attn_coverage = self.decoder(current_tgt, decoder_hidden, encoder_output, g_t, teach, decoder_attn_coverage) \n",
    "            if attns[\"std\"] == None:\n",
    "                attns[\"std\"] = decoder_attn_std\n",
    "                attns[\"coverage\"] = decoder_attn_coverage\n",
    "            else:\n",
    "                attns[\"std\"].append(decoder_attn_std)\n",
    "                attns[\"coverage\"].append(decoder_attn_coverage)\n",
    "            tem = decoder_output.view(1, batch_size, -1) # 1, batch, output\n",
    "            tem= F.log_softmax(tem, -1) # 1, batch, output\n",
    "            decoder_outputs[i] = tem\n",
    "            current_tgt = tem.max(2)[1].view(1, batch_size) # 1, batch\n",
    "        \n",
    "        return decoder_outputs, attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(DATA_SIZE, HIDDEN_SIZE, ENC_DROPOUT)\n",
    "attention = Attention(HIDDEN_SIZE)\n",
    "decoder = Decoder(HIDDEN_SIZE, DATA_SIZE, attention, DEC_DROPOUT)\n",
    "\n",
    "model = S2S(encoder, decoder, DATA_SIZE, GENERATION_LEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# generator parameters:', sum(param.numel() for param in model.parameters() if param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = DATA.vocab.stoi['<pad>']\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_IDX, reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, criterion, clip, teach):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for _, batch in enumerate(dataset):\n",
    "        covloss = 0\n",
    "        src = batch.src[0:2, :] # (s_len,batch)\n",
    "        tgt = batch.tgt# (t_len, batch)\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        outputs, attns = model(src, tgt, teach)\n",
    "        \n",
    "        cov = attns.get(\"coverage\", None)\n",
    "        std = attns.get(\"std\", None)\n",
    "        for ii in range(len(cov)):\n",
    "            covloss += torch.min(std[ii], cov[ii]).sum()            \n",
    "        covloss *= LAMBDA_COVERAGE\n",
    "        outputs = outputs.contiguous()\n",
    "        outputs = outputs.view(-1, DATA_SIZE)\n",
    "        tgt = tgt.contiguous()\n",
    "        tgt = tgt[1:].view(-1)\n",
    "        loss = criterion(outputs, tgt)\n",
    "        loss = loss + covloss\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=8, threshold=0.0001, threshold_mode='rel', cooldown=3, min_lr=0, eps=1e-9, verbose=False)\n",
    "plot_loss = []\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "    print(optimizer.param_groups[-1]['lr'])\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP, TEACH_RATE)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.2f}')\n",
    "    \n",
    "    plot_loss.append(train_loss)\n",
    "    scheduler.step(train_loss)\n",
    "    if epoch % 10 == 0: \n",
    "        model_name = f\"/opt/work/g1/s1910195/pt512/baselinenew_{epoch}.pt\"\n",
    "        para_name = f\"/opt/work/g1/s1910195/pt512/baselinenew_para{epoch}.pt\"\n",
    "        torch.save(model, model_name) \n",
    "        checkpoint = {\n",
    "                      \"net\": model.state_dict(),\n",
    "                      \"optimizer\": optimizer.state_dict(),\n",
    "                      \"epoch\": epoch+1,\n",
    "                      \"scheduler\": scheduler.state_dict(),\n",
    "                      \"loss\": plot_loss}\n",
    "        torch.save(checkpoint, para_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload checkpoint\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=8, threshold=0.0001, threshold_mode='rel', cooldown=3, min_lr=0, eps=1e-9, verbose=False)\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "path_checkpoint = \"/opt/work/g1/s1910195/pt512/baselinenew_para_12.pt\" # checkpoint path\n",
    "checkpoint = torch.load(path_checkpoint)\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "start_epoch = checkpoint['epoch']\n",
    "scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "plot_loss = checkpoint['loss']\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP, TEACH_RATE)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.2f}')\n",
    "    \n",
    "    plot_loss.append(train_loss)\n",
    "    scheduler.step(train_loss)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        model_name = f\"/opt/work/g1/s1910195/pt512/baselinenew_{epoch}.pt\"\n",
    "        para_name = f\"/opt/work/g1/s1910195/pt512/baselinenew_para_{epoch}.pt\"\n",
    "        torch.save(model, model_name) \n",
    "        checkpoint = {\n",
    "                      \"net\": model.state_dict(),\n",
    "                      \"optimizer\": optimizer.state_dict(),\n",
    "                      \"epoch\": epoch+1,\n",
    "                      \"scheduler\": scheduler.state_dict(),\n",
    "                      \"loss\": plot_loss}\n",
    "        torch.save(checkpoint, para_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('c:/users/derri/PycharmProjects/exp/pt/baselinenew_40.pt', device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(\n",
    "        path='c:/users/derri/PycharmProjects/exp/finaltest/base/s4.csv',\n",
    "        format='csv',\n",
    "        fields=[('src', DATA), ('tgt', DATA)],\n",
    "        skip_header = True)\n",
    "\n",
    "test_dataloader = BucketIterator(\n",
    "    test_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataset):\n",
    "    \n",
    "    model.eval()\n",
    "    teach = 0\n",
    "    for _, batch in enumerate(dataset):   \n",
    "        src = batch.src[0:2, :] # (len,batch)\n",
    "        tgt = batch.tgt # (len,batch)\n",
    "        outputs, attns = model(src, tgt, teach)        \n",
    "        outputs = outputs.contiguous()\n",
    "        res = outputs.max(2)[1]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = eval(model, test_dataloader)\n",
    "print(sss.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "print(DATA.vocab.itos[1])\n",
    "for i in gen_text:\n",
    "    for j in range(len(i)):\n",
    "        tt = DATA.vocab.itos[i[j].cpu().numpy().tolist()]\n",
    "        res[j].append(tt)\n",
    "#print(res)\n",
    "for c in res:\n",
    "    sent = \"\"\n",
    "    for d in c:\n",
    "        sent += d\n",
    "        sent += ' '\n",
    "        if d == '<eos>':\n",
    "            #print(sent)\n",
    "            break\n",
    "    print(sent)\n",
    "    #print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
